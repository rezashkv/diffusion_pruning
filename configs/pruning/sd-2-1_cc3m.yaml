model:
  unet:
    pretrained_model_name_or_path: stabilityai/stable-diffusion-2-1
    input_perturbation: 0.0
    revision: null
    resolution: 256
    use_ema: false
    noise_offset: 0.0
    prediction_type: v_prediction
    max_scheduler_steps: null
    unet_down_blocks:
      - CrossAttnDownBlock2DHalfGated
      - CrossAttnDownBlock2DHalfGated
      - CrossAttnDownBlock2DHalfGated
      - DownBlock2DHalfGated

    unet_mid_block: UNetMidBlock2DCrossAttnWidthGated

    unet_up_blocks:
      - UpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated

    gated_ff: true
    ff_gate_width: 32

  hypernet:
    weight_norm: false
    linear_bias: true

  quantizer:
    quantizer_T: 0.4
    quantizer_base: 3
    num_arch_vq_codebook_embeddings: 16
    arch_vq_beta: 0.25
    depth_order: [-1, -2, 0, 1, -3, -4, 2, 3, -5, -6, 4, 5, -7, 6]
    non_zero_width: true
    resource_aware_normalization: false

data:
  dataset_name: null
  data_files: null
  dataset_config_name: null
  data_dir: "path/to/conceptual_captions"

  train_data_dir: "training"
  train_data_file: "Train-GCC-training.tsv"
  train_bad_images_path: "path/to/train_cc3m_bad_images.txt"
  max_train_samples: null

  validation_data_dir: "validation"
  validation_data_file: "Validation-GCC-1.1.0-Validation.tsv"
  validation_bad_images_path: "/path/to/validation_cc3m_bad_images.txt"
  max_validation_samples: null


  image_column: "image"
  caption_column: "caption"
  prompts: null
  max_generated_samples: 32
  dataloader:
    dataloader_num_workers: 0
    train_batch_size: 128
    validation_batch_size: 32
    image_generation_batch_size: 4
    center_crop: false
    random_flip: true

training:
  num_train_epochs: null
  max_train_steps: 12000
  hypernet_pretraining_steps: 500
  validation_steps: 500
  image_logging_steps: 500
  mixed_precision: null
  gradient_accumulation_steps: 1
  gradient_checkpointing: false
  local_rank: -1
  num_inference_steps: 50
  allow_tf32: false
  enable_xformers_memory_efficient_attention: false

  losses:
    diffusion_loss:
      snr_gamma: 5.0

    resource_loss:
      type: log
      weight: 1.0
      pruning_target: 0.8

    quantization_loss:
      weight: 1.0

    contrastive_clip_loss:
      arch_vector_temperature: 0.03
      prompt_embedding_temperature: 0.03
      weight: 100.0

    std_loss:
      weight: 0.0

    max_loss:
      weight: 1.0

    distillation_loss:
      weight: 1.0

    block_loss:
      weight: 1.0

  optim:
    hypernet_learning_rate: 2e-4
    quantizer_learning_rate: 2e-4
    unet_learning_rate: 5e-5
    quantizer_weight_decay: 0.00
    hypernet_weight_decay: 0.00
    unet_weight_decay: 0.00
    scale_lr: true
    lr_scheduler: "constant_with_warmup"
    lr_warmup_steps: 100
    use_8bit_adam: false
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1e-08
    max_grad_norm: 1.0

  hf_hub:
    push_to_hub: false
    hub_token: null
    hub_model_id: null

  logging:
    logging_dir: "path/to/logs/"
    report_to: "wandb"
    wandb_log_dir: "path/to/wandb/logs/"
    checkpoints_total_limit: 1
    auto_checkpoint_step: false
    resume_from_checkpoint: null
    tracker_project_name: "text2image-dynamic-pruning"
