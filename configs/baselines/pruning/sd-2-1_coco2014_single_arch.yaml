model:
  unet:
    pretrained_model_name_or_path: stabilityai/stable-unet-2-1
    input_perturbation: 0.0
    revision: null
    resolution: 256
    use_ema: false
    noise_offset: 0.0
    prediction_type: v_prediction
    max_scheduler_steps: null
    unet_down_blocks:
      - CrossAttnDownBlock2DHalfGated
      - CrossAttnDownBlock2DHalfGated
      - CrossAttnDownBlock2DHalfGated
      - DownBlock2DHalfGated

    unet_mid_block: UNetMidBlock2DCrossAttnWidthGated

    unet_up_blocks:
      - UpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated

    gated_ff: true
    ff_gate_width: 32

  hypernet:
    weight_norm: false
    linear_bias: true
    single_arch_param: true # if true, train a single experts for all prompts (used as a baseline in the paper)

  quantizer:
    quantizer_T: 0.4
    quantizer_base: 3
    num_arch_vq_codebook_embeddings: 8
    arch_vq_beta: 0.25
    depth_order: [-1, -2, 0, 1, -3, -4, 2, 3, -5, -6, 4, 5, -7, 6]
    non_zero_width: true
    resource_aware_normalization: false
    optimal_transport: false

data:
  dataset_name: coco
  data_files: null
  dataset_config_name: null
  data_dir: "path/to/coco"

  max_train_samples: null
  max_validation_samples: null
  year: 2014 # 2014 or 2017. 2014 is used in the paper.

  image_column: "image"
  caption_column: "caption"

  prompts: null
  max_generated_samples: 2

  dataloader:
    dataloader_num_workers: 0
    train_batch_size: 64
    validation_batch_size: 16
    image_generation_batch_size: 4
    center_crop: false
    random_flip: true

training:
  num_train_epochs: null
  max_train_steps: 5000
  hypernet_pretraining_steps: 500
  validation_steps: 1000
  image_logging_steps: 1000
  num_inference_steps: 50 # number of scheduler steps to run for image generation

  mixed_precision: null
  gradient_accumulation_steps: 1
  gradient_checkpointing: false
  local_rank: -1
  allow_tf32: false
  enable_xformers_memory_efficient_attention: false

  losses:
    diffusion_loss:
      snr_gamma: 5.0
      weight: 1.0

    resource_loss:
      type: log
      weight: 2.0
      pruning_target: 0.6

    contrastive_loss:
      arch_vector_temperature: 0.03
      prompt_embedding_temperature: 0.03
      weight: 0.0

    distillation_loss:
      weight: 0.0

    block_loss:
      weight: 0.0

    std_loss:
      weight: 0.0

    max_loss:
      weight: 0.0


  optim:
    hypernet_learning_rate: 2e-4
    quantizer_learning_rate: 2e-4
    unet_learning_rate: 5e-5

    quantizer_weight_decay: 0.00
    hypernet_weight_decay: 0.00
    unet_weight_decay: 0.00

    use_8bit_adam: false
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1e-08

    scale_lr: true
    lr_scheduler: "constant_with_warmup" # see pdm.utils.arg_utils for available options
    lr_warmup_steps: 100


  hf_hub:
    push_to_hub: false
    hub_token: null
    hub_model_id: null

  logging:
    logging_dir: "path/to/logs/"

    report_to: "wandb"
    tracker_project_name: "text2image-dynamic-pruning"
    wandb_log_dir: "path/to/wandb"

    checkpoints_total_limit: 1
    auto_checkpoint_step: false
    resume_from_checkpoint: null # or latest

