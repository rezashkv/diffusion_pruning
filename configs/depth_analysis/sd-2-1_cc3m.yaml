model:
  unet:
    pretrained_model_name_or_path: stabilityai/stable-diffusion-2-1
    input_perturbation: 0.0
    revision: null
    resolution: 256
    use_ema: false
    noise_offset: 0.0
    prediction_type: epsilon
    unet_down_blocks:
      - CrossAttnDownBlock2DHalfGated
      - CrossAttnDownBlock2DHalfGated
      - CrossAttnDownBlock2DHalfGated
      - DownBlock2DHalfGated

    unet_mid_block: UNetMidBlock2DCrossAttnWidthGated
      
    unet_up_blocks:
      - UpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated
      - CrossAttnUpBlock2DHalfGated

    gated_ff: true
    ff_gate_width: 32

  hypernet:
    hypernet_sparsity: 0
    weight_norm: true
    inner_dim: 1024

  quantizer:
    quantizer_T: 0.4
    quantizer_base: 3.0
    num_arch_vq_codebook_embeddings: 256
    arch_vq_beta: 0.25
    depth_order: [-1, -2, -3, -4, -5, 0, 1, 2, -6, -7, 3, 4]


data:
  dataset_name: null
  data_files: null
  dataset_config_name: null
  data_dir: "/fs/vulcan-datasets/conceptual_captions"

  train_data_dir: "training"
  train_data_file: "Train_GCC-training.tsv"
  train_bad_images_path: "./data/train_cc3m_bad_images.txt"
  max_train_samples: 1000

  validation_data_dir: "validation"
  validation_data_file: "Validation_GCC-1.1.0-Validation.tsv"
  validation_bad_images_path: "./data/validation_cc3m_bad_images.txt"
  max_validation_samples: 1000

  image_column: "image"
  caption_column: "caption"
  prompts: null
  max_generated_samples: 32
  dataloader:
    dataloader_num_workers: 0
    train_batch_size: 36
    validation_batch_size: 4
    center_crop: false
    random_flip: true


training:
  num_train_epochs: 100
  max_train_steps: null
  validation_epochs: 1
  mixed_precision: null
  gradient_accumulation_steps: 1
  gradient_checkpointing: false
  local_rank: -1
  num_inference_steps: 100
  allow_tf32: false
  enable_xformers_memory_efficient_attention: false

  losses:
    diffusion_loss:
      snr_gamma: null

    resource_loss:
      type: log
      weight: 1.0
      pruning_target: 0.8

    quantization_loss:
      weight: 1.0

    contrastive_clip_loss:
      temperature: 1.0
      weight: 0.1

  optim:
    hypernet_learning_rate: 0.01
    quantizer_learning_rate: 0.001
    scale_lr: false
    lr_scheduler: "constant"
    lr_warmup_steps: 500
    use_8bit_adam: false
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_weight_decay: 0.01
    adam_epsilon: 1e-08
    max_grad_norm: 1.0

  hf_hub:
    push_to_hub: false
    hub_token: null
    hub_model_id: null

  logging:
    logging_dir: "/fs/nexus-scratch/rezashkv/research/logs/"
    report_to: "wandb"
    checkpointing_steps: 1000
    checkpoints_total_limit: 1
    resume_from_checkpoint: "latest"
    tracker_project_name: "text2image-dynamic-pruning"

